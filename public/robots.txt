# robots.txt for Protégé Lecture+
# https://protegelecture.org/robots.txt

# Allow all crawlers
User-agent: *
Allow: /
Allow: /books
Allow: /books/*
Allow: /groups
Allow: /groups/*
Allow: /events
Allow: /events/*
Allow: /about
Allow: /contact

# Disallow admin pages and private areas
Disallow: /admin/
Disallow: /admin/*
Disallow: /login
Disallow: /api/

# Disallow search result pages with query parameters
Disallow: /*?*search=
Disallow: /*?*filter=

# Google bot specific rules
User-agent: Googlebot
Allow: /
Disallow: /admin/
Disallow: /login

# Bing bot specific rules
User-agent: Bingbot
Allow: /
Disallow: /admin/
Disallow: /login

# Crawl-delay for aggressive crawlers
User-agent: *
Crawl-delay: 1

# Sitemap location
Sitemap: https://protegelecture.org/sitemap.xml

